# Importing essential libraries for our analysis
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Loading the dataset (obtained from Kaggle)
df = pd.read_csv("Telco-Customer-Churn.csv")

# ------------------ Initial Data Exploration ------------------

print("First 5 rows:")
print(df.head().to_markdown(index=False, numalign='left', stralign='left'))  # Nicely formatted table
print("\nData types and missing values:")
print(df.info())

# We observe:
# * 'TotalCharges' is an object type but should be numeric
# * Some missing values in 'TotalCharges'

# ------------------ Data Cleaning & Preprocessing ------------------

# Converting 'TotalCharges' to numeric, filling missing values with median
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())

# Dropping unnecessary 'customerID'
df.drop('customerID', axis=1, inplace=True)

# ------------------ Exploratory Data Analysis (EDA) ------------------

# Churn distribution
plt.figure(figsize=(8, 5))
sns.countplot(x='Churn', data=df)
plt.title('Churn Distribution')
plt.ylabel('Number of Customers')
plt.savefig("churn_distribution.png")  # Save the plot
plt.show()

print("\nChurn Proportion:")
print(df['Churn'].value_counts(normalize=True))

# Churn by different factors
for col in ['gender', 'SeniorCitizen', 'Partner', 'Dependents']:
    plt.figure(figsize=(10, 5))
    sns.countplot(x=col, hue='Churn', data=df)
    plt.title(f'Churn Distribution by {col}')
    plt.ylabel('Number of Customers')
    plt.savefig(f"churn_by_{col}.png")  # Save each plot
    plt.show()

# Distribution of Tenure
plt.figure(figsize=(10, 6))
sns.histplot(df['tenure'], kde=True)
plt.title('Tenure Distribution')
plt.xlabel('Tenure (months)')
plt.savefig("tenure_distribution.png")
plt.show()

# Correlation Matrix
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.savefig("correlation_matrix.png")
plt.show()

# ------------------ Feature Engineering ------------------

# Create new features to capture customer behavior

df['TenureMonths'] = df['tenure']  # Assuming 'tenure' is in months
df['HasPhoneService'] = df['PhoneService'].apply(lambda x: 1 if x == 'Yes' else 0)

# ... (Create more features like contract type dummies, total services used, etc.)

# One-hot encode categorical variables
df = pd.get_dummies(df, drop_first=True)

# ------------------ Model Building & Evaluation ------------------

# Splitting data into training and testing sets
X = df.drop('Churn', axis=1)
y = df['Churn']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Logistic Regression Model
model_lr = LogisticRegression(random_state=42)
model_lr.fit(X_train, y_train)
y_pred_lr = model_lr.predict(X_test)

# Random Forest Model
model_rf = RandomForestClassifier(n_estimators=100, random_state=42) 
model_rf.fit(X_train, y_train)
y_pred_rf = model_rf.predict(X_test)

# Model Evaluation
print("Logistic Regression:")
print(classification_report(y_test, y_pred_lr))
print("\nRandom Forest:")
print(classification_report(y_test, y_pred_rf))

# ... (Add more sophisticated model evaluation like ROC curves, cross-validation)

# ------------------ Insights & Recommendations ------------------

# (Based on the model results, analysis, and feature importance, provide actionable recommendations to the business)

#  "Customers with shorter tenure and higher monthly charges are more likely to churn. Offer targeted retention programs to these segments." 
